# ‚úÖ Configuraci√≥n: Gemini 2.5 Flash

## üìã Modelo Configurado

**Modelo:** `gemini-2.5-flash`  
**API:** Google AI Studio  
**Ubicaci√≥n:** Definido en `lib/api-handlers/ai/gemini.ts`

---

## üîß Archivos Actualizados

### **1. Handler Principal de Gemini**
**Archivo:** `lib/api-handlers/ai/gemini.ts` (l√≠nea 21)

```typescript
const GEMINI_MODEL = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
```

Este es el archivo principal que maneja todas las llamadas a Gemini API desde:
- `lib/gemini/parser.ts` ‚Üí `agenticParse()`
- Llamadas directas a `/api/ai/gemini`

### **2. Fallback de OpenRouter**
**Archivo:** `lib/api-handlers/ai/openrouter/structured.ts`

```typescript
const model = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
```

Cuando OpenRouter falla, usa Gemini como fallback.

---

## ‚öôÔ∏è Variables de Entorno

### **Desarrollo Local** (`.env.local`)

```env
# API Key de Google AI Studio (OBLIGATORIO)
GEMINI_API_KEY=AIzaSy...tu_key_aqui

# Modelo (OPCIONAL - ya est√° en el c√≥digo por defecto)
GEMINI_MODEL=gemini-2.5-flash

# Supabase (OBLIGATORIO)
VITE_SUPABASE_URL=https://tu-proyecto.supabase.co
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### **Producci√≥n en Vercel**

Configurar en: **Vercel Dashboard ‚Üí Settings ‚Üí Environment Variables**

```env
GEMINI_API_KEY=AIzaSy...tu_key_aqui
GEMINI_MODEL=gemini-2.5-flash
```

Aplicar a: **Production, Preview, Development**

---

## üöÄ Deploy a Vercel

### **Paso 1: Commit y Push**

```bash
git add .
git commit -m "feat: Configure Gemini 2.5 Flash model"
git push
```

### **Paso 2: Verificar Variables en Vercel**

1. Ve a tu proyecto en Vercel
2. Settings ‚Üí Environment Variables
3. Verifica que `GEMINI_API_KEY` est√© configurada
4. (Opcional) Agrega `GEMINI_MODEL=gemini-2.5-flash`

### **Paso 3: Redeploy**

Vercel har√° deploy autom√°ticamente con el push, o puedes forzar redeploy:
- Deployments ‚Üí (√∫ltimo deploy) ‚Üí ... ‚Üí Redeploy

---

## ‚úÖ Verificaci√≥n

### **En Desarrollo Local:**

Despu√©s de `npm run dev:full`, busca en los logs del terminal:

```
[Gemini Handler] Using model: gemini-2.5-flash
```

### **En Producci√≥n (Vercel):**

Verifica en los logs de Vercel (Runtime Logs):

```
[Gemini Handler] Using model: gemini-2.5-flash
```

---

## ‚ö†Ô∏è Importante: Disponibilidad del Modelo

**NOTA:** `gemini-2.5-flash` puede no estar disponible p√∫blicamente en Google AI Studio a√∫n.

### **Si ves errores tipo:**
```
Error: Model 'gemini-2.5-flash' not found
```

**Opciones:**

1. **Verificar disponibilidad:** Ve a https://aistudio.google.com/ y verifica qu√© modelos est√°n disponibles

2. **Usar modelo alternativo temporal:**
   ```env
   # En .env.local o Vercel
   GEMINI_MODEL=gemini-2.0-flash-exp
   ```

3. **Usar Gemini 1.5 Flash (estable):**
   ```env
   GEMINI_MODEL=gemini-1.5-flash-002
   ```

---

## üìä Modelos Disponibles en AI Studio

| Modelo | Estado | Ventajas |
|--------|--------|----------|
| `gemini-2.5-flash` | ‚ö†Ô∏è Experimental/Beta | M√°s reciente, mejor rendimiento |
| `gemini-2.0-flash-exp` | ‚úÖ Disponible | R√°pido, experimental |
| `gemini-1.5-flash-002` | ‚úÖ Estable | Confiable, probado |
| `gemini-1.5-pro-002` | ‚úÖ Estable | M√°s preciso, m√°s lento |

---

## üîç Troubleshooting

### **Error: "Empty response from Gemini"**

**Causas posibles:**

1. **Modelo no existe:** `gemini-2.5-flash` podr√≠a no estar disponible
   - **Soluci√≥n:** Usar `gemini-2.0-flash-exp` o `gemini-1.5-flash-002`

2. **API Key inv√°lida:** La key est√° expirada o mal configurada
   - **Soluci√≥n:** Regenerar key en https://aistudio.google.com/app/apikey

3. **Contenido bloqueado:** El PDF tiene contenido que Gemini bloquea por seguridad
   - **Soluci√≥n:** Verificar el contenido del PDF

4. **Cambios no desplegados:** El c√≥digo local no est√° en Vercel
   - **Soluci√≥n:** `git push` para deployar

### **Error: "Model not found"**

```bash
# Cambiar temporalmente el modelo
# En Vercel: Settings ‚Üí Environment Variables
GEMINI_MODEL=gemini-2.0-flash-exp

# O en .env.local para desarrollo
GEMINI_MODEL=gemini-2.0-flash-exp
```

### **Verificar qu√© modelo se est√° usando:**

**Logs del servidor (development):**
```
[Gemini Handler] Using model: gemini-2.5-flash
```

**Logs de Vercel (production):**
1. Vercel Dashboard ‚Üí Tu proyecto
2. Deployments ‚Üí (√∫ltimo deploy)
3. Runtime Logs
4. Busca: `[Gemini Handler] Using model:`

---

## üìù Flujo de Datos

```
Usuario sube PDF
    ‚Üì
Frontend extrae texto
    ‚Üì
lib/gemini/parser.ts ‚Üí agenticParse()
    ‚Üì
Llama a ‚Üí /api/ai/gemini
    ‚Üì
lib/api-handlers/ai/gemini.ts
    ‚Üì
Usa GEMINI_MODEL = 'gemini-2.5-flash'
    ‚Üì
Google AI Studio API
    ‚Üì
Respuesta JSON estructurada
```

---

## ‚úÖ Checklist de Configuraci√≥n

- [x] Modelo configurado en `lib/api-handlers/ai/gemini.ts`
- [x] Fallback configurado en `lib/api-handlers/ai/openrouter/structured.ts`
- [ ] `GEMINI_API_KEY` en `.env.local` (desarrollo)
- [ ] `GEMINI_API_KEY` en Vercel (producci√≥n)
- [ ] `git push` para deployar cambios
- [ ] Verificar logs: `[Gemini Handler] Using model: gemini-2.5-flash`
- [ ] Probar extracci√≥n de callsheet

---

**Fecha:** 2025-01-22  
**Estado:** ‚úÖ Configurado  
**Modelo:** `gemini-2.5-flash`  
**Pr√≥ximo paso:** Deploy a Vercel y verificar funcionamiento

